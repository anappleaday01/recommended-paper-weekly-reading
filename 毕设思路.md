确定数据集
DAIC-WOZ、CMDC等
- 数据处理：
	- 去除静音段（找vad技术[ **Silero-VAD**](https://blog.csdn.net/weixin_31569663/article/details/156554749);[简单代码-mfcc静音段阈值](https://blog.csdn.net/weixin_38468077/article/details/121677376)；deepseek三段（纯声学特征【无静音】、韵律特征【包含静音】、静音模式特征）），
	- 噪音去除（pyAudacity降噪（12dB）；
	- 对齐，
	- 元音提取（针对元音进行特征提取，而不是一个句子）
- 特征提取：
	- compare_2016集
	- 查找论文，了解论文里提到的特征集，针对性提取某些特征集
- 特征选择：
	- 先对特征打标签、分类，再做互信息投影，可视化。
	- 然后引入对抗消偏，只留下纯粹的生理声学特征；
	- 解耦训练，先训练一个解纠缠模型（VAE 或 对抗网络），利用其产生的注意力权重或贡献度评分，引入一个 “特征门控（Feature Gating）” 机制。在 Encoder 输入 6373 维特征时，加上一层可学习的掩码（Mask） $W$。损失函数： 让 $W$ 在最小化抑郁分类误差的同时，最大化对文本识别的干扰。从“掩码”中回溯原始特征通过训练，Mask $W$ 中数值最高的维度，对应的就是 ComParE 中最纯净的生理指标。
- 针对不同数据集中特征子集不完全一样
	- 使用“共识筛选法”（Consensus Filtering）不要在每个数据集上独立运行筛选，而是采用 Meta-selection 的逻辑：
		- Rank Aggregation（秩聚合）： 在数据集 A、B、C 上分别对 6373 维进行评分，然后计算它们的平均排名。
		- 核心子集（Core Subset）： 只有在所有（或大多数）数据集中都排名前 100 的特征，才被定义为“抑郁症通用生物标志物”。
	- 从“单一特征”提升到“特征域（Feature Domains）”虽然数据集 A 选出的是 Jitter_local，数据集 B 选出的是 Shimmer_apq3，但它们都属于**“声门源动力学（Glottal Source Dynamics）”**这一类

证明实验：
- 线性探针 (Linear Probing)： 尝试用第一阶段选出的 50 维生理特征，去线性预测 WavLM 内部的高维神经元激活值。如果相关性极高，你就向世界证明了：“WavLM 之所以预测得准，是因为它在暗中捕捉了我发现的这些生理特征。”
- SHAP 交互： 展示特征之间不是简单的加法，而是复杂的非线性关系
- 临床与生物学验证：
	- 跨语种验证，在英文集上解耦出的这套物理指标，在中文集上同样有效如中文MODMA (Mobile Depression Monitoring Analysis)兰州大学发布的中文抑郁症数据集；
		- 引入“稳定性分数”（Stability Index）
		- 如果一个特征在 DAIC-WOZ 中表现极好，但在 MODMA 中完全失效，说明它可能携带了某种“文化或语言特异性”。
		- 专门写一个章节讨论：“哪些特征是全人类通用的抑郁指标（如声门震动），哪些是受文化语境影响的（如韵律起伏）。
	- 元音空间压缩 (VSA)： 这是生物学上的证据。抑郁症导致构音肌肉无力，/a/, /i/, /u/ 的共振峰分布会缩水。你要用第一阶段选出的特征来量化这个“缩水”。
问题：
- 对抗消偏和解耦训练的区别，顺序上的先后
- 互信息提供可解释性图片，对于对抗消偏的分析与验证，初始化解耦训练的特征门控掩码
- 对于静音段段处理：不能无差别切，也要注意不能太激进，切掉弱语音和气声；采用多模态特征分离，分离三种特征类型（纯声学特征【无静音】、韵律特征【包含静音】、静音模式特征）。将静音相关特征单独标记，在互信息投影中观察位置，讨论临床意义。
- 降噪策略对比，选几个方案看效果，说明降噪方法的选择与理由，以及参数设置和鲁棒性分析，保守降噪，保护有临床价值的声学特征
- 特征提取级别：音频、句子、音素，联用？音素级别可解释性强，但是对齐精度敏感，数据碎片化，噪音强；音频级是整体全局，句子级是韵律变化，音素级是发音细节
- 要考虑人口统计信息，数据的不平衡性
	消融实验，公平性分析，在不同年龄、性别上
- 与现有量表的关系，采用phq-8问卷的语音还是非结构化的问答对话数据还是朗读文本（没有文本干扰，不需要对齐，精细发音分析）的语音
- 基线实验是什么？
	在哪里用到预训练大模型？    线性探针?
	后续使用模型的选择